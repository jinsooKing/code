# GEMINI VS HUMAN

1번 문제

난이도 하

전통적인 프로그래밍 방식과 머신러닝 방식의 가장 근본적인 차이점은 무엇이며, 
머신러닝이 데이터를 통해 "학습"한다는 것은 어떤 의미인지 설명해주세요.

ME : 전통적인 프로그래밍 방식으로 문제를 해결한다는 것은 A~Z까지 모든것을 오류없는 문법으로 명확히 정의하는 것이라고,
생각하고 머신러닝은 결과를 도출하는 과정을 사람이 잘 설계해주는 방식으로 문제를 해결하는 차이가 있다고 생각한다.
그리고 데이터를 통해 학습한다는 것은 현상을 가장 잘 설명해주는 N-1 차원 표현을 찾는 과정이라고 생각해.

AI : 전통적인 프로그래밍은 규칙을 기반으로 접근하고 머신러닝은 데이터를 기반으로 접근하며 패턴을 인식하고 이를 일반화
한다. 데이터로 학습한다는 것은 모델이 주어진 데이터를 이용해서 내부 파라미터를 스스로 조정해나가는 과정을 의미한다.
현상을 가장 잘 설명해주는 N-1차원을 찾는 과정을 학습이라고 말할 수 없다. 학습은 보다 넓은 개념이다.
차원 축소 관점에서는 설명이 맞다고 할 수 있지만 머신러닝 전체를 포괄하는 정의라고 보기 어렵다.
'주어진 데이터를 활용하여 특정 목적을 더 잘 수행할 수 있도록 모델의 내부 파라미터나 구조를 스스로 개선하고
일반화된 패턴을 찾아가는 과정'을 의미한다고 할 수 있다.



2번 문제

난이도 하

머신러닝의 주요 학습 방법 세 가지와 어떤 종류의 문제를 해결하는데 사용되는 지, 
각 방법의 핵심 특징은 무엇인지 설명해주세요.

ME : 지도학습은 정답 레이블을 주고 학습을 시키고 비지도학습은 정답레이블 없이 학습을 시키며,
강화학습은 학습데이터랑 정답레이블 둘 다 없이 환경과 에이전트와의 상호작용을 통한 보상체계를 이용하여 학습시킨다.

AI : 
지도학습은 정답이 있는 데이터를 사용하여 학습시키며 모델은 입력과 정답 사이의 관계를 학습합니다.
주로 분류나 회귀 문제를 해결합니다.

비지도학습은 정답이 없는 데이터를 사용하여 학습시키며 모델은 데이터 자체의 숨겨진 구조, 패턴, 관계를 스스로 학습합니다.
군집화, 차원 축소(시각화, 특징 추출), 연관 규칙 학습등의 문제를 해결합니다.

강화학습은 에이전트가 환경과 상호작용하며 학습합니다. 에이전트는 STATE에서 ACTION을 취하고 그 결과로 ENVIRONMENT로
부터 REWARD OR PENALTY를 받습니다. 에이전트의 목표는 REWARD의 SUM을 최대화하는 POLICY를 학습합니다. 레이블된 데이터가
직접 주어지기 보다는 시행착오를 통해 학습합니다.


3번 문제

난이도 하-중

분류문제와 회귀문제 각각에 사용되는 대표적인 성능 평가 지표를 2개 이상씩 언급하고, 각 지표가 의미하는것을 설명하시오.

ME :

SSE, MSE, RMSE, CCE(BIANARY, CATEGORICAL) 말고 모르겠다.

AI : 

회귀 => 
1. MSE(평균 제곱 오차) : 오차를 제곱해서 평균낸 값이며 outlier에 민감하고 값이 작을수록 좋다.

2. RMSE(평균 제곱근 오차) : 오차 제곱 평균에다가 루트 씌운값, 오차를 실제 값과 같은 단위로 
                        해석할 수 있다는 장점.(제곱을 안하기 때문에)

3. MAE(평균 절대 오차) : 오차의 절댓값의 평균값, outlier에 덜 민감하고 작을수록 좋다.\

4. R-squared(결정 계수) : 모델이 실제 값의 분산을 얼마나 잘 설명하는지를 나타낸다.

                        수식 = 1 - (SUM((실제 - 예측)^2) / SUM((실제 - 예측평균)^2))

                        값이 1에 가까울수록 회귀 모델이 종속 변수의 변동을 잘 설명한다는 의미이다.
                        1에 가깝다고 인과관계가 있음을 의미하지 않습니다.
                        변동을 잘 설명한다는 것이 이해가 잘 안간다면 정답에 가까운 예측을 한다는 뜻입니다.
                        

분류 =>
1. Accuracy(정확도) : 전체 예측 중 올바르게 예측한 건수의 비율. 클래스 분포가 불균형하면 성능이 안나온다.
                        정답도 10개 오답도 10개면 성능을 보이겠지만 정답이 10갠데 오답이 10000개면 정확도 지표는
                        매우 매우 낮게 나올 것이기 때문이다.

2. Precision(정밀도) : P중에 TP의 비율. TP/TP+FP / 맞다고 한 것중 진짜 맞는 비율
                        FP를 낮추는 것이 중요할 때 사용하면 효과가 좋다.
                        
                        스팸분류기에서 스팸이라고 예측한 애들(TP+FP) 중에 실제 스팸 메일의 비율(TP) 이런 문제에선
                        스팸이 아닌데 스팸이라고 예측한 애들(FP)가 줄어들수록 좋은 모델이 된다.

3. Recall(재현율) : Sensitivity(민감도)라고도 불리며 실제 정답 중에(TP+FN) 얼마나 제대로 예측했는지(TP)의 비율.
                    암 진단 모델에서 실제 암 환자(TP+FP) 중 암이라고 진단한 환자(TP)의 비율.
                    
                    암인데 암이 아니라고 예측한 환자(FN)를 낮추는 것이 중요할 때 효과가 좋다.

4. f1-score : 정밀도와 재현율의 조화 평균. 두 지표가 모두 중요하거나, 클래스 불균형이 있을 때 유용

5. AUC-ROC(Area Under the ROC Curve) : ROC 곡선 아래 면적. 클래스불균형에 비교적 덜 민감. 1에 가까울 수록 우수.




4번 문제