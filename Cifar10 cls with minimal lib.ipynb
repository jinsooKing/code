{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f6434e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621bdef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'test_image\\L.jpeg'\n",
    "\n",
    "test_img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "cv2.imshow('loaded image', test_img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "82985f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 400, 3)\n",
      "uint8\n",
      "<memory at 0x000001EC4E27AD40>\n",
      "<built-in method astype of numpy.ndarray object at 0x000001EC4D48D530>\n"
     ]
    }
   ],
   "source": [
    "print(test_img.shape)\n",
    "print(test_img.dtype)\n",
    "print(test_img.data)\n",
    "print(test_img.astype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b402131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 77 105 112]\n",
      "  [ 80 108 115]\n",
      "  [ 86 112 118]\n",
      "  ...\n",
      "  [ 25  24  26]\n",
      "  [ 26  25  27]\n",
      "  [ 27  26  28]]]\n",
      "tensor([[[ 77, 105, 112],\n",
      "         [ 80, 108, 115],\n",
      "         [ 86, 112, 118],\n",
      "         ...,\n",
      "         [ 25,  24,  26],\n",
      "         [ 26,  25,  27],\n",
      "         [ 27,  26,  28]]], dtype=torch.uint8)\n",
      "tensor([[[0.3020, 0.4118, 0.4392],\n",
      "         [0.3137, 0.4235, 0.4510],\n",
      "         [0.3373, 0.4392, 0.4627],\n",
      "         ...,\n",
      "         [0.0980, 0.0941, 0.1020],\n",
      "         [0.1020, 0.0980, 0.1059],\n",
      "         [0.1059, 0.1020, 0.1098]]])\n",
      "tensor([[[0.3020, 0.4118, 0.4392],\n",
      "         [0.3216, 0.4314, 0.4588],\n",
      "         [0.3451, 0.4549, 0.4824],\n",
      "         ...,\n",
      "         [0.6667, 0.7686, 0.8235],\n",
      "         [0.6627, 0.7686, 0.8235],\n",
      "         [0.6627, 0.7686, 0.8235]]])\n",
      "tensor([[[0.3020, 0.4118, 0.4392],\n",
      "         [0.3137, 0.4235, 0.4510],\n",
      "         [0.3373, 0.4392, 0.4627],\n",
      "         ...,\n",
      "         [0.0980, 0.0941, 0.1020],\n",
      "         [0.1020, 0.0980, 0.1059],\n",
      "         [0.1059, 0.1020, 0.1098]]])\n"
     ]
    }
   ],
   "source": [
    "print(test_img[:1])\n",
    "\n",
    "test_img_tensor = torch.tensor(test_img)\n",
    "print(test_img_tensor[:1])\n",
    "\n",
    "test_img_tensor = test_img_tensor / 255\n",
    "print(test_img_tensor[:1])\n",
    "\n",
    "to_tensor = transforms.ToTensor()\n",
    "test_img_tensor2 = to_tensor(test_img)\n",
    "print(test_img_tensor2.T[:1])\n",
    "print(test_img_tensor2.permute(1,2,0)[:1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bb9e4caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform(img): #ndarray (h, w, c) -> tensor (c/255, h/255, w/255)\n",
    "    \"\"\"\n",
    "    \n",
    "    img = torch.tensor(img)\n",
    "    img = img.permute(2,0,1)\n",
    "    img = img/255\n",
    "    \n",
    "    \"\"\"\n",
    "    img = transforms.ToTensor()(img)\n",
    "    img = (img - 0.5) / 0.5 # transforms.Noramilze((0.5,0.5,0.5), (0.5))\n",
    "    \n",
    "    return img\n",
    "\n",
    "test_img_transform = transform(test_img)\n",
    "\n",
    "test_img_transform.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a7ae95",
   "metadata": {},
   "source": [
    "1. 이미지를 cv2.imread(path, cv2.imread_color) 등을 통해 읽으면 nd.array 형태로 저장됨.\n",
    "2. ToTensor는 PIL 또는 ndarray를 C * H * W 형태로 치환하고 255로 나눠 정규화해줌.\n",
    "3. pytorch에서 blabla.T 처럼 전치하는 것은 위험함. .T는 마지막 두차원만 전치시켜줌.\n",
    "    예를 들어 (C, H, W) 형태의 텐서를 .T하면 (C, W, H)가 됨. 즉 원하는 차원변경이 아닐 수 있다.\n",
    "    따라서, .permute(*dims) 함수를 사용해 전치시키는 습관이 필요하다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "861b68ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_path = 'test_image'\n",
    "\n",
    "trainset= torchvision.datasets.CIFAR10(root=download_path, train=True,\n",
    "                                      download=True, transform = transform)\n",
    "\n",
    "testset= torchvision.datasets.CIFAR10(root=download_path, train=False,\n",
    "                                      download=True, transform = transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "aa7c0485",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('airplane', 'automobile', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "894c43c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "print(trainset[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e1e67a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jinai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
